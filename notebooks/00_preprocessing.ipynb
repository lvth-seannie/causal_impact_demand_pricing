{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kstest, anderson, probplot\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normality(df):\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        ks_stat, ks_p_value = kstest(df[col], 'norm', args=(df[col].mean(), df[col].std()))\n",
    "        print(f'Kolmogorov-Smirnov test p-value: {ks_p_value}')\n",
    "        if ks_p_value < 0.05:\n",
    "            print(f'{col} is likely not normally distributed based on KS Test.\\n')\n",
    "        else:\n",
    "            print(f'{col} is likely normally distributed based on KS Test.\\n')\n",
    "            \n",
    "        # Anderson-Darling Test\n",
    "        ad_result = anderson(df[col], dist='norm')\n",
    "        print(f'Anderson-Darling Test Statistic: {ad_result.statistic}\\n')\n",
    "        for i in range(len(ad_result.critical_values)):\n",
    "            print(f'Critical value for {ad_result.significance_level[i]}%: {ad_result.critical_values[i]}')\n",
    "            if ad_result.statistic > ad_result.critical_values[i]:\n",
    "                print(f'{col} is likely not normally distributed at {ad_result.significance_level[i]}% level.')\n",
    "            else:\n",
    "                print(f'{col} is likely normally distributed at {ad_result.significance_level[i]}% level.')\n",
    "                \n",
    "        # visual check for normality\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        probplot(df[col], dist=\"norm\", plot=plt)\n",
    "        plt.title(f'Q-Q plot for {col}')\n",
    "        plt.show()\n",
    "            \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.title(f'Histogram for {col}')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def check_outliers_iqr(df):\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Identifying outliers\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        print(f'Outliers in {col}:')\n",
    "        print(outliers)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded the data!\n"
     ]
    }
   ],
   "source": [
    "fpath_01 = '../datasets/raw/consumer_airfare/table1_top1000_contiguous_state_city-pair_markets.csv'\n",
    "fpath_02 = '../datasets/raw/consumer_airfare/table1a_all_US_airport_pair_markets.csv'\n",
    "fpath_03 = '../datasets/raw/consumer_airfare/table2_top1000_city-pair.csv'\n",
    "fpath_04 = '../datasets/raw/consumer_airfare/table3_city-pair_markets_with_substantial_increase_inAvg.csv'\n",
    "fpath_05 = '../datasets/raw/consumer_airfare/table4_city-pair_markets_with_substantial_decrease_inAvg.csv'\n",
    "fpath_06 = '../datasets/raw/consumer_airfare/table5_detailed_fare_info_highest_lowest_fare_markets_under750Miles.csv'\n",
    "fpath_07 = '../datasets/raw/consumer_airfare/table7_fare_premiums_for_select_cities_with_more_than_20_passengers_per_day.csv'\n",
    "df1 = pd.read_csv(fpath_01, sep=';')\n",
    "df1a = pd.read_csv(fpath_02, sep=';')\n",
    "df2 = pd.read_csv(fpath_03, sep=';')\n",
    "df3 = pd.read_csv(fpath_04, sep=';')\n",
    "df4 = pd.read_csv(fpath_05, sep=';')\n",
    "df5 = pd.read_csv(fpath_06, sep=';')\n",
    "df7 = pd.read_csv(fpath_07, sep=';')\n",
    "print('successfully loaded the data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115035 entries, 0 to 115034\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Year            115035 non-null  int64  \n",
      " 1   quarter         115035 non-null  int64  \n",
      " 2   citymarketid_1  115035 non-null  object \n",
      " 3   citymarketid_2  115035 non-null  int64  \n",
      " 4   city1           115035 non-null  object \n",
      " 5   city2           115035 non-null  object \n",
      " 6   nsmiles         115035 non-null  int64  \n",
      " 7   passengers      115035 non-null  object \n",
      " 8   fare            115035 non-null  float64\n",
      " 9   carrier_lg      115035 non-null  object \n",
      " 10  large_ms        115035 non-null  float64\n",
      " 11  fare_lg         115035 non-null  float64\n",
      " 12  carrier_low     115032 non-null  object \n",
      " 13  lf_ms           115032 non-null  float64\n",
      " 14  fare_low        115032 non-null  float64\n",
      " 15  table_1_flag    115035 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(6)\n",
      "memory usage: 14.0+ MB\n",
      "--------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249884 entries, 0 to 249883\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Year            249884 non-null  int64  \n",
      " 1   quarter         249884 non-null  int64  \n",
      " 2   citymarketid_1  249884 non-null  int64  \n",
      " 3   citymarketid_2  249884 non-null  int64  \n",
      " 4   city1           249884 non-null  object \n",
      " 5   city2           249884 non-null  object \n",
      " 6   airportid_1     249884 non-null  int64  \n",
      " 7   airportid_2     249884 non-null  int64  \n",
      " 8   airport_1       249884 non-null  object \n",
      " 9   airport_2       249884 non-null  object \n",
      " 10  nsmiles         249884 non-null  object \n",
      " 11  passengers      249884 non-null  object \n",
      " 12  fare            249884 non-null  object \n",
      " 13  carrier_lg      248334 non-null  object \n",
      " 14  large_ms        248334 non-null  float64\n",
      " 15  fare_lg         248334 non-null  object \n",
      " 16  carrier_low     248262 non-null  object \n",
      " 17  lf_ms           248262 non-null  float64\n",
      " 18  fare_low        248262 non-null  object \n",
      "dtypes: float64(2), int64(6), object(11)\n",
      "memory usage: 36.2+ MB\n",
      "--------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8268 entries, 0 to 8267\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Year            8268 non-null   int64  \n",
      " 1   quarter         8268 non-null   int64  \n",
      " 2   citymarketid    8268 non-null   int64  \n",
      " 3   city            8268 non-null   object \n",
      " 4   markets         8268 non-null   int64  \n",
      " 5   cur_passengers  8268 non-null   object \n",
      " 6   cur_fare        8268 non-null   float64\n",
      " 7   cur_yield       8268 non-null   float64\n",
      " 8   distance        8268 non-null   object \n",
      " 9   ly_passengers   8265 non-null   object \n",
      " 10  ly_fare         8265 non-null   float64\n",
      " 11  ly_yield        8265 non-null   float64\n",
      " 12  ly_distance     8265 non-null   object \n",
      "dtypes: float64(4), int64(4), object(5)\n",
      "memory usage: 839.8+ KB\n",
      "--------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3052 entries, 0 to 3051\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Year                3052 non-null   object \n",
      " 1   quarter             3052 non-null   int64  \n",
      " 2   citymarketid_1      3052 non-null   object \n",
      " 3   citymarketid_2      3052 non-null   object \n",
      " 4   city1               3052 non-null   object \n",
      " 5   city2               3052 non-null   object \n",
      " 6   cur_passengers      3052 non-null   object \n",
      " 7   cur_fare            3052 non-null   float64\n",
      " 8   ly_fare             3052 non-null   float64\n",
      " 9   ly_passengers       3052 non-null   object \n",
      " 10  amount_change       3052 non-null   float64\n",
      " 11  percent_change      3052 non-null   float64\n",
      " 12  amount_change_pax   3052 non-null   object \n",
      " 13  percent_change_pax  3052 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 333.9+ KB\n",
      "--------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2989 entries, 0 to 2988\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Year                2989 non-null   object \n",
      " 1   quarter             2989 non-null   int64  \n",
      " 2   citymarketid_1      2989 non-null   object \n",
      " 3   citymarketid_2      2989 non-null   object \n",
      " 4   city1               2989 non-null   object \n",
      " 5   city2               2989 non-null   object \n",
      " 6   cur_passengers      2989 non-null   object \n",
      " 7   cur_fare            2989 non-null   float64\n",
      " 8   ly_fare             2989 non-null   float64\n",
      " 9   ly_passengers       2989 non-null   object \n",
      " 10  amount_change       2989 non-null   float64\n",
      " 11  percent_change      2989 non-null   float64\n",
      " 12  amount_change_pax   2989 non-null   object \n",
      " 13  percent_change_pax  2989 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(8)\n",
      "memory usage: 327.0+ KB\n",
      "--------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14881 entries, 0 to 14880\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Year               14881 non-null  object \n",
      " 1   quarter            14881 non-null  int64  \n",
      " 2   mkt_fare           14881 non-null  float64\n",
      " 3   citymarketid_1     14881 non-null  object \n",
      " 4   citymarketid_2     14881 non-null  object \n",
      " 5   city1              14881 non-null  object \n",
      " 6   city2              14881 non-null  object \n",
      " 7   carairlineid       14881 non-null  object \n",
      " 8   car                14881 non-null  object \n",
      " 9   carpax             14881 non-null  object \n",
      " 10  carpaxshare        14881 non-null  float64\n",
      " 11  caravgfare         14881 non-null  float64\n",
      " 12  fareinc_min        14881 non-null  int64  \n",
      " 13  fareinc_minpaxsh   14881 non-null  float64\n",
      " 14  fareinc_max        14881 non-null  int64  \n",
      " 15  fare_inc_maxpaxsh  14881 non-null  float64\n",
      " 16  fare_inc_x3paxsh   14881 non-null  float64\n",
      "dtypes: float64(6), int64(3), object(8)\n",
      "memory usage: 1.9+ MB\n",
      "--------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22619 entries, 0 to 22618\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Year             22619 non-null  int64  \n",
      " 1   quarter          22619 non-null  int64  \n",
      " 2   citymarketid     22619 non-null  int64  \n",
      " 3   cityname         22419 non-null  object \n",
      " 4   airportid        22619 non-null  int64  \n",
      " 5   apt              22619 non-null  object \n",
      " 6   TotalMkts        22619 non-null  int64  \n",
      " 7   TotalFaredPax    22619 non-null  object \n",
      " 8   TotalPerLFMkts   22619 non-null  float64\n",
      " 9   TotalAvgHubFare  22619 non-null  float64\n",
      " 10  TotalPerPrem     22619 non-null  float64\n",
      " 11  SHMkts           22316 non-null  float64\n",
      " 12  SHPax            22316 non-null  object \n",
      " 13  SHPerLFMkts      22316 non-null  float64\n",
      " 14  SHAvgHubFare     22316 non-null  float64\n",
      " 15  SHPerPrem        22316 non-null  object \n",
      " 16  LHMkts           22321 non-null  float64\n",
      " 17  LHPax            22321 non-null  object \n",
      " 18  LHPerLFMkts      22321 non-null  float64\n",
      " 19  LHAvgHubFare     22321 non-null  float64\n",
      " 20  LHPerPrem        22321 non-null  float64\n",
      "dtypes: float64(10), int64(5), object(6)\n",
      "memory usage: 3.6+ MB\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dfs = [df1, df1a, df2, df3, df4, df5, df7]\n",
    "for df in dfs:\n",
    "    cols_to_drop = list(df.filter(regex='^tbl|^Geocoded_City'))\n",
    "    if cols_to_drop:\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "    df.shape\n",
    "    df.info()\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year              0\n",
      "quarter           0\n",
      "citymarketid_1    0\n",
      "citymarketid_2    0\n",
      "city1             0\n",
      "city2             0\n",
      "nsmiles           0\n",
      "passengers        0\n",
      "fare              0\n",
      "carrier_lg        0\n",
      "large_ms          0\n",
      "fare_lg           0\n",
      "carrier_low       3\n",
      "lf_ms             3\n",
      "fare_low          3\n",
      "table_1_flag      0\n",
      "dtype: int64\n",
      "-------------------------------------------------------------------------------------------\n",
      "Year                 0\n",
      "quarter              0\n",
      "citymarketid_1       0\n",
      "citymarketid_2       0\n",
      "city1                0\n",
      "city2                0\n",
      "airportid_1          0\n",
      "airportid_2          0\n",
      "airport_1            0\n",
      "airport_2            0\n",
      "nsmiles              0\n",
      "passengers           0\n",
      "fare                 0\n",
      "carrier_lg        1550\n",
      "large_ms          1550\n",
      "fare_lg           1550\n",
      "carrier_low       1622\n",
      "lf_ms             1622\n",
      "fare_low          1622\n",
      "dtype: int64\n",
      "-------------------------------------------------------------------------------------------\n",
      "Year              0\n",
      "quarter           0\n",
      "citymarketid      0\n",
      "city              0\n",
      "markets           0\n",
      "cur_passengers    0\n",
      "cur_fare          0\n",
      "cur_yield         0\n",
      "distance          0\n",
      "ly_passengers     3\n",
      "ly_fare           3\n",
      "ly_yield          3\n",
      "ly_distance       3\n",
      "dtype: int64\n",
      "-------------------------------------------------------------------------------------------\n",
      "Year                  0\n",
      "quarter               0\n",
      "citymarketid_1        0\n",
      "citymarketid_2        0\n",
      "city1                 0\n",
      "city2                 0\n",
      "cur_passengers        0\n",
      "cur_fare              0\n",
      "ly_fare               0\n",
      "ly_passengers         0\n",
      "amount_change         0\n",
      "percent_change        0\n",
      "amount_change_pax     0\n",
      "percent_change_pax    0\n",
      "dtype: int64\n",
      "-------------------------------------------------------------------------------------------\n",
      "Year                  0\n",
      "quarter               0\n",
      "citymarketid_1        0\n",
      "citymarketid_2        0\n",
      "city1                 0\n",
      "city2                 0\n",
      "cur_passengers        0\n",
      "cur_fare              0\n",
      "ly_fare               0\n",
      "ly_passengers         0\n",
      "amount_change         0\n",
      "percent_change        0\n",
      "amount_change_pax     0\n",
      "percent_change_pax    0\n",
      "dtype: int64\n",
      "-------------------------------------------------------------------------------------------\n",
      "Year                 0\n",
      "quarter              0\n",
      "mkt_fare             0\n",
      "citymarketid_1       0\n",
      "citymarketid_2       0\n",
      "city1                0\n",
      "city2                0\n",
      "carairlineid         0\n",
      "car                  0\n",
      "carpax               0\n",
      "carpaxshare          0\n",
      "caravgfare           0\n",
      "fareinc_min          0\n",
      "fareinc_minpaxsh     0\n",
      "fareinc_max          0\n",
      "fare_inc_maxpaxsh    0\n",
      "fare_inc_x3paxsh     0\n",
      "dtype: int64\n",
      "-------------------------------------------------------------------------------------------\n",
      "Year                 0\n",
      "quarter              0\n",
      "citymarketid         0\n",
      "cityname           200\n",
      "airportid            0\n",
      "apt                  0\n",
      "TotalMkts            0\n",
      "TotalFaredPax        0\n",
      "TotalPerLFMkts       0\n",
      "TotalAvgHubFare      0\n",
      "TotalPerPrem         0\n",
      "SHMkts             303\n",
      "SHPax              303\n",
      "SHPerLFMkts        303\n",
      "SHAvgHubFare       303\n",
      "SHPerPrem          303\n",
      "LHMkts             298\n",
      "LHPax              298\n",
      "LHPerLFMkts        298\n",
      "LHAvgHubFare       298\n",
      "LHPerPrem          298\n",
      "dtype: int64\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(df.isna().sum())\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print('-------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['table_1_flag'], inplace=True)\n",
    "\n",
    "df1a.drop(columns=['airportid_1', 'airportid_2', 'airport_1', 'airport_2'], inplace=True)\n",
    "\n",
    "df7.drop(columns=['cityname', 'airportid', 'apt', 'TotalMkts', 'SHMkts', 'SHPerLFMkts', 'LHMkts', 'LHPerLFMkts'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handling data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                int64\n",
       "quarter             int64\n",
       "citymarketid_1     object\n",
       "citymarketid_2      int64\n",
       "city1              object\n",
       "city2              object\n",
       "nsmiles             int64\n",
       "passengers          int64\n",
       "fare              float64\n",
       "carrier_lg         object\n",
       "large_ms          float64\n",
       "fare_lg           float64\n",
       "carrier_low        object\n",
       "lf_ms             float64\n",
       "fare_low          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['passengers'] = df1['passengers'].astype(str).str.replace(',', '', regex=False)\n",
    "df1['passengers'] = pd.to_numeric(df1['passengers'], errors='coerce')\n",
    "df1['passengers'] = df1['passengers'].astype(int)\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249884 entries, 0 to 249883\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Year            249884 non-null  int64  \n",
      " 1   quarter         249884 non-null  int64  \n",
      " 2   citymarketid_1  249884 non-null  int64  \n",
      " 3   citymarketid_2  249884 non-null  int64  \n",
      " 4   city1           249884 non-null  object \n",
      " 5   city2           249884 non-null  object \n",
      " 6   nsmiles         249884 non-null  float64\n",
      " 7   passengers      249884 non-null  int64  \n",
      " 8   fare            249884 non-null  float64\n",
      " 9   carrier_lg      248334 non-null  object \n",
      " 10  large_ms        248334 non-null  float64\n",
      " 11  fare_lg         248334 non-null  float64\n",
      " 12  carrier_low     248262 non-null  object \n",
      " 13  lf_ms           248262 non-null  float64\n",
      " 14  fare_low        248262 non-null  float64\n",
      "dtypes: float64(6), int64(5), object(4)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df1a_num_cols = ['fare', 'lf_ms', 'large_ms', 'fare_lg', 'fare_low']\n",
    "\n",
    "df1a['passengers'] = df1a['passengers'].astype(str).str.replace(',', '', regex=False)\n",
    "df1a['passengers'] = pd.to_numeric(df1a['passengers'], errors='coerce')\n",
    "df1a['passengers'] = df1a['passengers'].astype(int)\n",
    "\n",
    "df1a['nsmiles'] = df1a['nsmiles'].str.replace(',', '.', regex=False)  \n",
    "df1a['nsmiles'] = df1a['nsmiles'].replace(['NA', 'N/A', 'None'], np.nan)  \n",
    "df1a['nsmiles'] = pd.to_numeric(df1a['nsmiles'], errors='coerce')\n",
    "\n",
    "for col in df1a_num_cols:\n",
    "    if df1a[col].dtype == 'object':\n",
    "        df1a[col] = df1a[col].astype(str).str.replace(',', '', regex=False)\n",
    "        \n",
    "        if col in ['large_ms', 'fare_lg', 'fare_low']:\n",
    "            df1a[col] = df1a[col].replace(['NA', 'N/A', 'None'], np.nan)\n",
    "        df1a[col] = pd.to_numeric(df1a[col], errors='coerce')\n",
    "        \n",
    "df1a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                int64\n",
       "quarter             int64\n",
       "citymarketid        int64\n",
       "city               object\n",
       "markets             int64\n",
       "cur_passengers      Int64\n",
       "cur_fare          float64\n",
       "cur_yield         float64\n",
       "distance          float64\n",
       "ly_passengers       Int64\n",
       "ly_fare           float64\n",
       "ly_yield          float64\n",
       "ly_distance       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df2.columns:\n",
    "    if any(x in col for x in ['passengers', 'distance']):\n",
    "        if any(y in col for y in ['passengers']):\n",
    "            df2[col] = df2[col].astype(str).str.replace(',', '', regex=True).str.strip()\n",
    "            df2[col] = pd.to_numeric(df2[col], errors='coerce').astype(pd.Int64Dtype())\n",
    "        else:\n",
    "            df2[col] = df2[col].astype(str).str.replace(',', '', regex=False)\n",
    "            df2[col] = df2[col].replace(['NA', 'N/A', 'None', np.inf, -np.inf], np.nan)\n",
    "            df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                   object\n",
       "quarter                 int64\n",
       "citymarketid_1         object\n",
       "citymarketid_2         object\n",
       "city1                  object\n",
       "city2                  object\n",
       "cur_passengers          Int64\n",
       "cur_fare              float64\n",
       "ly_fare               float64\n",
       "ly_passengers           Int64\n",
       "amount_change         float64\n",
       "percent_change        float64\n",
       "amount_change_pax       Int64\n",
       "percent_change_pax    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df3.columns:\n",
    "    if col in ['amount_change_pax', 'cur_passengers', 'ly_passengers']:\n",
    "        df3[col] = df3[col].astype(str).str.replace(',', '', regex=True).str.strip()\n",
    "        df3[col] = pd.to_numeric(df3[col], errors='coerce')\n",
    "        df3[col] = df3[col].astype(pd.Int64Dtype())\n",
    "\n",
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                   object\n",
       "quarter                 int64\n",
       "citymarketid_1         object\n",
       "citymarketid_2         object\n",
       "city1                  object\n",
       "city2                  object\n",
       "cur_passengers          Int64\n",
       "cur_fare              float64\n",
       "ly_fare               float64\n",
       "ly_passengers           Int64\n",
       "amount_change         float64\n",
       "percent_change        float64\n",
       "amount_change_pax       Int64\n",
       "percent_change_pax    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df4.columns:\n",
    "    if col in ['amount_change_pax', 'cur_passengers', 'ly_passengers']:\n",
    "        df4[col] = df4[col].astype(str).str.replace(',', '', regex=True).str.strip()\n",
    "        df4[col] = pd.to_numeric(df4[col], errors='coerce')\n",
    "        df4[col] = df4[col].astype(pd.Int64Dtype())\n",
    "\n",
    "df4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5['carpax'] = df5['carpax'].astype(str).str.replace(',', '', regex=False)\n",
    "df5['carpax'] = pd.to_numeric(df5['carpax'], errors='coerce')\n",
    "df5['carpax'] = df5['carpax'].astype(int)\n",
    "df5['carpax'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                 int64\n",
       "quarter              int64\n",
       "citymarketid         int64\n",
       "TotalFaredPax        int64\n",
       "TotalPerLFMkts     float64\n",
       "TotalAvgHubFare    float64\n",
       "TotalPerPrem       float64\n",
       "SHPax                Int64\n",
       "SHAvgHubFare       float64\n",
       "SHPerPrem          float64\n",
       "LHPax                Int64\n",
       "LHAvgHubFare       float64\n",
       "LHPerPrem          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7['TotalFaredPax'] = df7['TotalFaredPax'].astype(str).str.replace(',', '', regex=False).astype(int)\n",
    "\n",
    "df7_num_cols = ['SHPax', 'SHAvgHubFare', 'SHPerPrem', 'LHPax', 'LHAvgHubFare', 'LHPerPrem']\n",
    "# remove ',' with '' & 'NaN', 'NA', 'inf' with np.nan\n",
    "for col in df7_num_cols:\n",
    "    if any(x in col for x in ['SHPax', 'LHPax']):\n",
    "        df7[col] = df7[col].str.replace(',', '', regex=False)\n",
    "        df7[col] = pd.to_numeric(df7[col], errors='coerce').astype(pd.Int64Dtype())\n",
    "    else:\n",
    "        df7[col] = df7[col].astype(str).str.replace(',', '', regex=False)\n",
    "        df7[col] = df7[col].replace(['NaN', 'NA', np.inf, -np.inf], np.nan)\n",
    "        df7[col] = pd.to_numeric(df7[col], errors='coerce')\n",
    "            \n",
    "df7.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking if the data is normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1_num_cols = df1[['nsmiles', 'passengers', 'fare', 'large_ms', 'fare_lg', 'lf_ms', 'fare_low']]\n",
    "# check_normality(df1_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1a_num_cols = df1a[['large_ms', 'fare_lg', 'lf_ms', 'fare_low']]\n",
    "# check_normality(df1a_num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df7_num_cols = df7[['SHPax', 'SHAvgHubFare', 'SHPerPrem', 'LHPax', 'LHAvgHubFare', 'LHPerPrem']]\n",
    "# check_normality(df7_num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop missing values for df1 and df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(subset=['carrier_low', 'lf_ms', 'fare_low'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(subset=['ly_passengers', 'ly_fare', 'ly_yield', 'ly_distance'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                 0\n",
       "quarter              0\n",
       "citymarketid_1       0\n",
       "citymarketid_2       0\n",
       "city1                0\n",
       "city2                0\n",
       "nsmiles              0\n",
       "passengers           0\n",
       "fare                 0\n",
       "carrier_lg        1550\n",
       "large_ms          1550\n",
       "fare_lg           1550\n",
       "carrier_low       1622\n",
       "lf_ms             1622\n",
       "fare_low          1622\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1a.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute Iterative Imputer for missing values in normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                 0\n",
       "quarter              0\n",
       "citymarketid_1       0\n",
       "citymarketid_2       0\n",
       "city1                0\n",
       "city2                0\n",
       "nsmiles              0\n",
       "passengers           0\n",
       "fare                 0\n",
       "carrier_lg        1550\n",
       "large_ms          1550\n",
       "fare_lg           1550\n",
       "carrier_low       1622\n",
       "lf_ms             1622\n",
       "fare_low          1622\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1a.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                int64\n",
      "quarter             int64\n",
      "citymarketid_1      int64\n",
      "citymarketid_2      int64\n",
      "city1              object\n",
      "city2              object\n",
      "nsmiles           float64\n",
      "passengers          int64\n",
      "fare              float64\n",
      "carrier_lg         object\n",
      "large_ms          float64\n",
      "fare_lg           float64\n",
      "carrier_low        object\n",
      "lf_ms             float64\n",
      "fare_low          float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Year                 0\n",
       "quarter              0\n",
       "citymarketid_1       0\n",
       "citymarketid_2       0\n",
       "city1                0\n",
       "city2                0\n",
       "nsmiles              0\n",
       "passengers           0\n",
       "fare                 0\n",
       "carrier_lg        1550\n",
       "large_ms             0\n",
       "fare_lg              0\n",
       "carrier_low       1622\n",
       "lf_ms                0\n",
       "fare_low             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1a_imputed_cols = ['lf_ms', 'large_ms', 'fare_lg', 'fare_low']\n",
    "num_imputer = IterativeImputer(random_state=0, max_iter=20, tol=1e-3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df1a[df1a_imputed_cols] = scaler.fit_transform(df1a[df1a_imputed_cols])\n",
    "\n",
    "df1a_imputed_values = num_imputer.fit_transform(df1a[df1a_imputed_cols])\n",
    "\n",
    "df1a_imputed_df = pd.DataFrame(df1a_imputed_values, columns=df1a_imputed_cols, index=df1a.index)\n",
    "df1a[df1a_imputed_cols] = scaler.inverse_transform(df1a_imputed_df)\n",
    "\n",
    "print(df1a.dtypes)\n",
    "df1a.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                 0\n",
       "quarter              0\n",
       "citymarketid         0\n",
       "TotalFaredPax        0\n",
       "TotalPerLFMkts       0\n",
       "TotalAvgHubFare      0\n",
       "TotalPerPrem         0\n",
       "SHPax              303\n",
       "SHAvgHubFare       303\n",
       "SHPerPrem          303\n",
       "LHPax              298\n",
       "LHAvgHubFare       298\n",
       "LHPerPrem          298\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                 int64\n",
      "quarter              int64\n",
      "citymarketid         int64\n",
      "TotalFaredPax        int64\n",
      "TotalPerLFMkts     float64\n",
      "TotalAvgHubFare    float64\n",
      "TotalPerPrem       float64\n",
      "SHPax                int64\n",
      "SHAvgHubFare       float64\n",
      "SHPerPrem          float64\n",
      "LHPax                int64\n",
      "LHAvgHubFare       float64\n",
      "LHPerPrem          float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Year               0\n",
       "quarter            0\n",
       "citymarketid       0\n",
       "TotalFaredPax      0\n",
       "TotalPerLFMkts     0\n",
       "TotalAvgHubFare    0\n",
       "TotalPerPrem       0\n",
       "SHPax              0\n",
       "SHAvgHubFare       0\n",
       "SHPerPrem          0\n",
       "LHPax              0\n",
       "LHAvgHubFare       0\n",
       "LHPerPrem          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute missing values\n",
    "df7_imputed_cols = ['SHPax', 'SHAvgHubFare', 'SHPerPrem', 'LHPax', 'LHAvgHubFare', 'LHPerPrem']\n",
    "num_imputer = IterativeImputer(random_state=0, max_iter=20, tol=1e-3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df7[df7_imputed_cols] = scaler.fit_transform(df7[df7_imputed_cols])\n",
    "\n",
    "df7_imputed_values =num_imputer.fit_transform(df7[df7_imputed_cols])\n",
    "\n",
    "df7_imputed_df = pd.DataFrame(df7_imputed_values, columns=df7_imputed_cols, index=df7.index)\n",
    "df7[df7_imputed_cols] = scaler.inverse_transform(df7_imputed_df)\n",
    "\n",
    "# convert passenger columns to int \n",
    "df7['SHPax'] = df7['SHPax'].astype(int)\n",
    "df7['LHPax'] = df7['LHPax'].astype(int)\n",
    "\n",
    "print(df7.dtypes)\n",
    "df7.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute with the most frequent category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year              0\n",
       "quarter           0\n",
       "citymarketid_1    0\n",
       "citymarketid_2    0\n",
       "city1             0\n",
       "city2             0\n",
       "nsmiles           0\n",
       "passengers        0\n",
       "fare              0\n",
       "carrier_lg        0\n",
       "large_ms          0\n",
       "fare_lg           0\n",
       "carrier_low       0\n",
       "lf_ms             0\n",
       "fare_low          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1a['carrier_lg'] = df1a['carrier_lg'].replace('nan', np.nan)\n",
    "df1a['carrier_low'] = df1a['carrier_low'].replace('nan', np.nan)\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df1a['carrier_lg'] = cat_imputer.fit_transform(df1a[['carrier_lg']]).ravel()\n",
    "df1a['carrier_low'] = cat_imputer.fit_transform(df1a[['carrier_low']]).ravel()\n",
    "df1a.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfs has been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df1.to_csv('../datasets/processed/df1.csv', index=False)\n",
    "df1a.to_csv('../datasets/processed/df1a.csv', index=False)\n",
    "df2.to_csv('../datasets/processed/df2.csv', index=False)\n",
    "df3.to_csv('../datasets/processed/df3.csv', index=False)\n",
    "df4.to_csv('../datasets/processed/df4.csv', index=False)\n",
    "df5.to_csv('../datasets/processed/df5.csv', index=False)\n",
    "df7.to_csv('../datasets/processed/df7.csv', index=False)\n",
    "\n",
    "print('dfs has been saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_col(series):\n",
    "    if series.dtype == 'object':\n",
    "        series = series.str.replace('%', '', regex=False)\n",
    "        series = series.str.replace(',', '.', regex=False) \n",
    "        series = series.str.replace(',', '', regex=False)\n",
    "    numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "    return numeric_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1 = pd.read_csv('../datasets/processed/df1.csv', sep=',', decimal='.')\n",
    "df_t7 = pd.read_csv('../datasets/processed/df7.csv', sep=',', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting df_t1['citymarketid_1'] before cleaning/conversion ---\n",
      "Data Type: object\n",
      "Non-Null Count: 115032\n",
      "Unique values (sample):\n",
      "['32,575' '32,467' '31,703' '30,977' '30,397' '32,211' '30,721' '32,457'\n",
      " '30,194' '33,570' '30,325' '31,454' '31,453' '31,057' '31,295' '30,693'\n",
      " '30,466' '34,057' '31,650' '30,559' '30,423' '33,195' '33,192' '31,714'\n",
      " '30,994' '33,495' '31,136' '30,792' '34,614' '32,337' '31,066' '30,647'\n",
      " '34,100' '31,135' '33,105' '30,529' '31,123' '33,198' '30,713' '33,342'\n",
      " '33,214' '30,852' '34,492' '30,140' '34,321' '30,154' '30,198' '33,044'\n",
      " '31,995' '33,244']\n",
      "\n",
      "--- Applying cleaning steps to citymarketid_1 ---\n",
      "Removing commas...\n",
      "Unique values (sample) AFTER cleaning:\n",
      "['32575' '32467' '31703' '30977' '30397' '32211' '30721' '32457' '30194'\n",
      " '33570' '30325' '31454' '31453' '31057' '31295' '30693' '30466' '34057'\n",
      " '31650' '30559' '30423' '33195' '33192' '31714' '30994' '33495' '31136'\n",
      " '30792' '34614' '32337' '31066' '30647' '34100' '31135' '33105' '30529'\n",
      " '31123' '33198' '30713' '33342' '33214' '30852' '34492' '30140' '34321'\n",
      " '30154' '30198' '33044' '31995' '33244']\n",
      "\n",
      "--- Attempting Conversion to Int64 ---\n",
      "\n",
      "--- Checking df_t1['citymarketid_1'] AFTER conversion ---\n",
      "Data Type: Int64\n",
      "Non-Null Count: 115032\n",
      "Null Count: 0\n",
      "\n",
      "--- Verifying types before merge ---\n",
      "df_t1 citymarketid_1 dtype: Int64, Non-Nulls: 115032\n",
      "df_t1 citymarketid_2 dtype: Int64, Non-Nulls: 115032\n",
      "df_t7 citymarketid dtype: Int64, Non-Nulls: 22619\n",
      "\n",
      "Conversion appears successful, proceeding with merge...\n",
      "Number of rows in df_t7_final before duplicate check: 22619\n",
      "Number of duplicate key sets found in df_t7_final: 2798\n",
      "Handling duplicates by averaging values...\n",
      "Number of rows in df_t7_final after averaging duplicates: 19821\n",
      "\n",
      "--- Final merged DataFrame info: ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115032 entries, 0 to 115031\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Year                 115032 non-null  Int64  \n",
      " 1   quarter              115032 non-null  Int64  \n",
      " 2   citymarketid_1       115032 non-null  Int64  \n",
      " 3   citymarketid_2       115032 non-null  Int64  \n",
      " 4   city1                115032 non-null  object \n",
      " 5   city2                115032 non-null  object \n",
      " 6   nsmiles              115032 non-null  int64  \n",
      " 7   passengers           115032 non-null  int64  \n",
      " 8   fare                 115032 non-null  float64\n",
      " 9   carrier_lg           115032 non-null  object \n",
      " 10  large_ms             115032 non-null  float64\n",
      " 11  fare_lg              115032 non-null  float64\n",
      " 12  carrier_low          115032 non-null  object \n",
      " 13  lf_ms                115032 non-null  float64\n",
      " 14  fare_low             115032 non-null  float64\n",
      " 15  origin_fare_premium  112876 non-null  float64\n",
      " 16  origin_perc_lcc_pax  112876 non-null  float64\n",
      " 17  dest_fare_premium    112858 non-null  float64\n",
      " 18  dest_perc_lcc_pax    112858 non-null  float64\n",
      " 19  route_id             115032 non-null  object \n",
      "dtypes: Int64(4), float64(9), int64(2), object(5)\n",
      "memory usage: 18.0+ MB\n",
      "\n",
      "--- Final missing values AFTER MERGE: ---\n",
      "Year                      0\n",
      "quarter                   0\n",
      "citymarketid_1            0\n",
      "citymarketid_2            0\n",
      "city1                     0\n",
      "city2                     0\n",
      "nsmiles                   0\n",
      "passengers                0\n",
      "fare                      0\n",
      "carrier_lg                0\n",
      "large_ms                  0\n",
      "fare_lg                   0\n",
      "carrier_low               0\n",
      "lf_ms                     0\n",
      "fare_low                  0\n",
      "origin_fare_premium    2156\n",
      "origin_perc_lcc_pax    2156\n",
      "dest_fare_premium      2174\n",
      "dest_perc_lcc_pax      2174\n",
      "route_id                  0\n",
      "dtype: int64\n",
      "\n",
      "--- Final missing values AFTER HANDLING: ---\n",
      "Year                   0\n",
      "quarter                0\n",
      "citymarketid_1         0\n",
      "citymarketid_2         0\n",
      "city1                  0\n",
      "city2                  0\n",
      "nsmiles                0\n",
      "passengers             0\n",
      "fare                   0\n",
      "carrier_lg             0\n",
      "large_ms               0\n",
      "fare_lg                0\n",
      "carrier_low            0\n",
      "lf_ms                  0\n",
      "fare_low               0\n",
      "origin_fare_premium    0\n",
      "origin_perc_lcc_pax    0\n",
      "dest_fare_premium      0\n",
      "dest_perc_lcc_pax      0\n",
      "route_id               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inspecting df_t1['citymarketid_1'] before cleaning/conversion ---\")\n",
    "print(\"Data Type:\", df_t1['citymarketid_1'].dtype)\n",
    "print(\"Non-Null Count:\", df_t1['citymarketid_1'].notna().sum())\n",
    "print(\"Unique values (sample):\")\n",
    "try:\n",
    "    unique_vals = df_t1['citymarketid_1'].unique()\n",
    "    print(unique_vals[:50]) # shows values like '32,575'\n",
    "except Exception as e:\n",
    "    print(f\"Could not display unique values: {e}\")\n",
    "\n",
    "\n",
    "# --- Clean the string column BEFORE converting ---\n",
    "print(\"\\n--- Applying cleaning steps to citymarketid_1 ---\")\n",
    "\n",
    "# 1. Ensure it's treated as string and strip whitespace \n",
    "df_t1['citymarketid_1'] = df_t1['citymarketid_1'].astype(str).str.strip()\n",
    "\n",
    "# 2. Remove commas used as thousands separators\n",
    "print(\"Removing commas...\")\n",
    "df_t1['citymarketid_1'] = df_t1['citymarketid_1'].str.replace(',', '', regex=False)\n",
    "\n",
    "# Check unique values again AFTER cleaning to verify\n",
    "print(\"Unique values (sample) AFTER cleaning:\")\n",
    "unique_vals_cleaned = df_t1['citymarketid_1'].unique()\n",
    "print(unique_vals_cleaned[:50])\n",
    "\n",
    "# --- Convert to numeric AFTER cleaning ---\n",
    "print(\"\\n--- Attempting Conversion to Int64 ---\")\n",
    "df_t1['citymarketid_1'] = pd.to_numeric(df_t1['citymarketid_1'], errors='coerce').astype('Int64')\n",
    "# Also convert citymarketid_2 and df_t7['citymarketid']\n",
    "df_t1['citymarketid_2'] = pd.to_numeric(df_t1['citymarketid_2'], errors='coerce').astype('Int64')\n",
    "df_t7['citymarketid'] = pd.to_numeric(df_t7['citymarketid'], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "# --- Check conversion result ---\n",
    "print(\"\\n--- Checking df_t1['citymarketid_1'] AFTER conversion ---\")\n",
    "print(\"Data Type:\", df_t1['citymarketid_1'].dtype)\n",
    "print(\"Non-Null Count:\", df_t1['citymarketid_1'].notna().sum())\n",
    "print(\"Null Count:\", df_t1['citymarketid_1'].isna().sum()) \n",
    "\n",
    "\n",
    "# --- Verify types before merge ---\n",
    "print(\"\\n--- Verifying types before merge ---\")\n",
    "print(f\"df_t1 citymarketid_1 dtype: {df_t1['citymarketid_1'].dtype}, Non-Nulls: {df_t1['citymarketid_1'].notna().sum()}\")\n",
    "print(f\"df_t1 citymarketid_2 dtype: {df_t1['citymarketid_2'].dtype}, Non-Nulls: {df_t1['citymarketid_2'].notna().sum()}\")\n",
    "print(f\"df_t7 citymarketid dtype: {df_t7['citymarketid'].dtype}, Non-Nulls: {df_t7['citymarketid'].notna().sum()}\")\n",
    "\n",
    "\n",
    "# --- Proceed with merge only if conversion was successful ---\n",
    "if df_t1['citymarketid_1'].notna().sum() > 0:\n",
    "    print(\"\\nConversion appears successful, proceeding with merge...\")\n",
    "\n",
    "    # Ensure 'Year', 'quarter' have matching types\n",
    "    df_t1['Year'] = pd.to_numeric(df_t1['Year'], errors='coerce').astype('Int64')\n",
    "    df_t1['quarter'] = pd.to_numeric(df_t1['quarter'], errors='coerce').astype('Int64')\n",
    "    df_t7['Year'] = pd.to_numeric(df_t7['Year'], errors='coerce').astype('Int64')\n",
    "    df_t7['quarter'] = pd.to_numeric(df_t7['quarter'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Clean T7 columns and rename (using correct T7 column names from info())\n",
    "    df_t7_clean = df_t7[['Year', 'quarter', 'citymarketid', 'TotalPerPrem', 'TotalPerLFMkts']].copy()\n",
    "    df_t7_clean.rename(columns={'TotalPerPrem': 'city_fare_premium',\n",
    "                          'TotalPerLFMkts': 'city_perc_lcc_pax'}, inplace=True)\n",
    "    df_t7_final = df_t7_clean[['Year', 'quarter', 'citymarketid', 'city_fare_premium', 'city_perc_lcc_pax']]\n",
    "\n",
    "print(f\"Number of rows in df_t7_final before duplicate check: {len(df_t7_final)}\")\n",
    "key_cols = ['Year', 'quarter', 'citymarketid']\n",
    "\n",
    "# --- Check for duplicates based on merge keys ---\n",
    "num_duplicates = df_t7_final.duplicated(subset=key_cols).sum()\n",
    "print(f\"Number of duplicate key sets found in df_t7_final: {num_duplicates}\")\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    print(\"Handling duplicates by averaging values...\")\n",
    "    value_cols = ['city_fare_premium', 'city_perc_lcc_pax'] \n",
    "    \n",
    "    # Group by keys, calculate mean, reset index\n",
    "    df_t7_final = df_t7_final.groupby(key_cols, as_index=False)[value_cols].mean()\n",
    "    print(f\"Number of rows in df_t7_final after averaging duplicates: {len(df_t7_final)}\")\n",
    "\n",
    "    # Merge for Origin City\n",
    "    df_merged = pd.merge(df_t1, df_t7_final,\n",
    "                         left_on=['Year', 'quarter', 'citymarketid_1'],\n",
    "                         right_on=['Year', 'quarter', 'citymarketid'],\n",
    "                         how='left')\n",
    "    df_merged.rename(columns={'city_fare_premium': 'origin_fare_premium',\n",
    "                              'city_perc_lcc_pax': 'origin_perc_lcc_pax'}, inplace=True)\n",
    "\n",
    "    # Merge for Destination City\n",
    "    df_merged = pd.merge(df_merged, df_t7_final,\n",
    "                         left_on=['Year', 'quarter', 'citymarketid_2'],\n",
    "                         right_on=['Year', 'quarter', 'citymarketid'],\n",
    "                         how='left', suffixes=('_orig_temp', ''))\n",
    "    df_merged.rename(columns={'city_fare_premium': 'dest_fare_premium',\n",
    "                              'city_perc_lcc_pax': 'dest_perc_lcc_pax'}, inplace=True)\n",
    "\n",
    "    # Clean up columns\n",
    "    df_merged.drop(columns=['citymarketid_orig_temp', 'citymarketid'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Create route_id\n",
    "    df_merged['route_id'] = df_merged['citymarketid_1'].astype(str) + '_' + df_merged['citymarketid_2'].astype(str)\n",
    "\n",
    "    # Assign to df and check results\n",
    "    df = df_merged.copy()\n",
    "    print(\"\\n--- Final merged DataFrame info: ---\")\n",
    "    df.info()\n",
    "    print(\"\\n--- Final missing values AFTER MERGE: ---\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Handle remaining NAs (from non-matches)\n",
    "    fill_cols = ['origin_fare_premium', 'origin_perc_lcc_pax', 'dest_fare_premium', 'dest_perc_lcc_pax']\n",
    "    for col in fill_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0) # fill with 0 for no matching city market ids\n",
    "    \n",
    "    print(\"\\n--- Final missing values AFTER HANDLING: ---\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "else:\n",
    "    print(\"\\nMerge skipped: df_t1['citymarketid_1'] conversion still failed after cleaning.\")\n",
    "    print(\"If commas were removed and it still fails, re-inspect unique values for other issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Adding Holiday Features ---\n",
      "Generated US holidays from 1996 to 2024\n",
      "Applying holiday checks...\n",
      "\n",
      "Holiday features added:\n",
      "is_Q_with_NYD             29006\n",
      "is_Q_with_Memorial        29008\n",
      "is_Q_with_Jul4_Indep      29007\n",
      "is_Q_with_Labor           29007\n",
      "is_Q_with_Thx             28011\n",
      "is_Q_with_Christmas       28011\n",
      "is_Q_with_Any_Holiday    115032\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>citymarketid_1</th>\n",
       "      <th>citymarketid_2</th>\n",
       "      <th>city1</th>\n",
       "      <th>city2</th>\n",
       "      <th>nsmiles</th>\n",
       "      <th>passengers</th>\n",
       "      <th>fare</th>\n",
       "      <th>carrier_lg</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_fare_premium</th>\n",
       "      <th>dest_perc_lcc_pax</th>\n",
       "      <th>route_id</th>\n",
       "      <th>is_Q_with_NYD</th>\n",
       "      <th>is_Q_with_Memorial</th>\n",
       "      <th>is_Q_with_Jul4_Indep</th>\n",
       "      <th>is_Q_with_Labor</th>\n",
       "      <th>is_Q_with_Thx</th>\n",
       "      <th>is_Q_with_Christmas</th>\n",
       "      <th>is_Q_with_Any_Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>32575</td>\n",
       "      <td>32457</td>\n",
       "      <td>Los Angeles, CA (Metropolitan Area)</td>\n",
       "      <td>San Francisco, CA (Metropolitan Area)</td>\n",
       "      <td>372</td>\n",
       "      <td>16339</td>\n",
       "      <td>159.59</td>\n",
       "      <td>WN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031567</td>\n",
       "      <td>0.891767</td>\n",
       "      <td>32575_32457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>32467</td>\n",
       "      <td>31703</td>\n",
       "      <td>Miami, FL (Metropolitan Area)</td>\n",
       "      <td>New York City, NY (Metropolitan Area)</td>\n",
       "      <td>1118</td>\n",
       "      <td>15842</td>\n",
       "      <td>179.57</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033580</td>\n",
       "      <td>0.811460</td>\n",
       "      <td>32467_31703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>32575</td>\n",
       "      <td>31703</td>\n",
       "      <td>Los Angeles, CA (Metropolitan Area)</td>\n",
       "      <td>New York City, NY (Metropolitan Area)</td>\n",
       "      <td>2510</td>\n",
       "      <td>13767</td>\n",
       "      <td>399.68</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033580</td>\n",
       "      <td>0.811460</td>\n",
       "      <td>32575_31703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>31703</td>\n",
       "      <td>31454</td>\n",
       "      <td>New York City, NY (Metropolitan Area)</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>989</td>\n",
       "      <td>12511</td>\n",
       "      <td>176.63</td>\n",
       "      <td>B6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140200</td>\n",
       "      <td>0.969300</td>\n",
       "      <td>31703_31454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>30977</td>\n",
       "      <td>31703</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>New York City, NY (Metropolitan Area)</td>\n",
       "      <td>773</td>\n",
       "      <td>11466</td>\n",
       "      <td>184.79</td>\n",
       "      <td>UA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033580</td>\n",
       "      <td>0.811460</td>\n",
       "      <td>30977_31703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  quarter  citymarketid_1  citymarketid_2  \\\n",
       "0  2024        3           32575           32457   \n",
       "1  2024        3           32467           31703   \n",
       "2  2024        3           32575           31703   \n",
       "3  2024        3           31703           31454   \n",
       "4  2024        3           30977           31703   \n",
       "\n",
       "                                   city1  \\\n",
       "0    Los Angeles, CA (Metropolitan Area)   \n",
       "1          Miami, FL (Metropolitan Area)   \n",
       "2    Los Angeles, CA (Metropolitan Area)   \n",
       "3  New York City, NY (Metropolitan Area)   \n",
       "4                            Chicago, IL   \n",
       "\n",
       "                                   city2  nsmiles  passengers    fare  \\\n",
       "0  San Francisco, CA (Metropolitan Area)      372       16339  159.59   \n",
       "1  New York City, NY (Metropolitan Area)     1118       15842  179.57   \n",
       "2  New York City, NY (Metropolitan Area)     2510       13767  399.68   \n",
       "3                            Orlando, FL      989       12511  176.63   \n",
       "4  New York City, NY (Metropolitan Area)      773       11466  184.79   \n",
       "\n",
       "  carrier_lg  ...  dest_fare_premium  dest_perc_lcc_pax     route_id  \\\n",
       "0         WN  ...          -0.031567           0.891767  32575_32457   \n",
       "1         B6  ...           0.033580           0.811460  32467_31703   \n",
       "2         B6  ...           0.033580           0.811460  32575_31703   \n",
       "3         B6  ...          -0.140200           0.969300  31703_31454   \n",
       "4         UA  ...           0.033580           0.811460  30977_31703   \n",
       "\n",
       "   is_Q_with_NYD  is_Q_with_Memorial  is_Q_with_Jul4_Indep  is_Q_with_Labor  \\\n",
       "0              0                   0                     1                1   \n",
       "1              0                   0                     1                1   \n",
       "2              0                   0                     1                1   \n",
       "3              0                   0                     1                1   \n",
       "4              0                   0                     1                1   \n",
       "\n",
       "   is_Q_with_Thx  is_Q_with_Christmas is_Q_with_Any_Holiday  \n",
       "0              0                    0                     1  \n",
       "1              0                    0                     1  \n",
       "2              0                    0                     1  \n",
       "3              0                    0                     1  \n",
       "4              0                    0                     1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- Adding Holiday Features ---\")\n",
    "\n",
    "df['Year_n'] = df['Year'].astype(int)\n",
    "\n",
    "# Define major holidays/periods often affecting travel\n",
    "# (Thanksgiving and Christmas fall in Q4, New Year's Day in Q1, Memorial Day in Q2, July 4th/Labor Day in Q3)\n",
    "\n",
    "# Get US holidays for the range of years in the data\n",
    "min_year = df['Year_n'].min()\n",
    "max_year = df['Year_n'].max()\n",
    "try:\n",
    "    us_holidays = holidays.US(years=range(min_year, max_year + 1))\n",
    "    print(f\"Generated US holidays from {min_year} to {max_year}\")\n",
    "\n",
    "    # Function to check if key holidays fall within a quarter\n",
    "    def check_major_holidays(row):\n",
    "        year = row['Year_n']\n",
    "        quarter = row['quarter']\n",
    "        \n",
    "        # Q1: New Year's Day\n",
    "        has_nyd = 1 if quarter == 1 and pd.Timestamp(f'{year}-01-01') in us_holidays else 0\n",
    "        \n",
    "        # Q2: Memorial Day (Last Monday in May) - Check if May is in Q2\n",
    "        has_memorial = 1 if quarter == 2 and any(date.month == 5 and holiday == 'Memorial Day' for date, holiday in us_holidays.items() if date.year == year) else 0\n",
    "        \n",
    "        # Q3: July 4th, Independence Day - Check if Jul/Aug/Sep are in Q3\n",
    "        has_jul4 = 1 if quarter == 3 and \\\n",
    "            (pd.Timestamp(f'{year}-07-04') in us_holidays or \\\n",
    "             any(date.month == 9 and holiday == 'Independence Day' for date, holiday in us_holidays.items() if date.year == year)\n",
    "            ) else 0\n",
    "        \n",
    "        # Q3: Labor Day (First Monday in Sep) - Check if Jul/Aug/Sep are in Q3\n",
    "        has_labor = 1 if quarter == 3 and \\\n",
    "            (pd.Timestamp(f'{year}-09-01') in us_holidays or \\\n",
    "             any(date.month == 9 and holiday == 'Labor Day' for date, holiday in us_holidays.items() if date.year == year) \n",
    "            ) else 0\n",
    "        \n",
    "        # Q4: Thanksgiving (Fourth Thursday in Nov), Christmas Day\n",
    "        nov_dates = pd.date_range(start=f'{year}-11-01', end=f'{year}-11-30', freq='D')\n",
    "        thus = nov_dates[nov_dates.weekday == 3]\n",
    "        thx_date = thus[3] if len(thus) >= 4 else None\n",
    "        has_thx = 1 if quarter == 4 and (thx_date is not None and thx_date in us_holidays) else 0\n",
    "        \n",
    "        # Q4: Christmas Day (Dec 25)\n",
    "        has_christmas = 1 if quarter == 4 and pd.Timestamp(f'{year}-12-25') in us_holidays else 0\n",
    "\n",
    "        # Flag if *any* federal holiday falls in the quarter\n",
    "        has_any = 0\n",
    "        try:\n",
    "            # Define quarter start and end dates accurately\n",
    "            q_start_month = (quarter - 1) * 3 + 1\n",
    "            q_end_month = quarter * 3\n",
    "            start_date = pd.Timestamp(f'{year}-{q_start_month:02d}-01')\n",
    "            if q_end_month == 12:\n",
    "                end_date = pd.Timestamp(f'{year}-12-31')\n",
    "            else:\n",
    "                next_q_start_month = q_end_month + 1\n",
    "                end_date = pd.Timestamp(f'{year}-{next_q_start_month:02d}-01') - pd.Timedelta(days=1)\n",
    "\n",
    "            # Check if any holiday falls within the quarter range\n",
    "            for holiday_date in us_holidays:\n",
    "                if holiday_date.year == year:\n",
    "                    holiday_ts = pd.Timestamp(holiday_date)\n",
    "                    if start_date <= holiday_ts <= end_date:\n",
    "                        has_any = 1\n",
    "                        break # found one, no need to check further for this quarter\n",
    "        except Exception as e:\n",
    "            has_any = 0 # default to 0 if range check fails\n",
    "\n",
    "        return pd.Series([has_nyd, has_memorial, has_jul4, has_labor, has_thx, has_christmas, has_any])\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing holidays or defining function: {e}\")\n",
    "    def check_major_holidays(row):\n",
    "        return pd.Series([0, 0, 0, 0, 0, 0, 0])\n",
    "    \n",
    "# Apply the function row-wise\n",
    "print(\"Applying holiday checks...\")\n",
    "holiday_cols = ['is_Q_with_NYD', 'is_Q_with_Memorial', 'is_Q_with_Jul4_Indep', 'is_Q_with_Labor', 'is_Q_with_Thx', 'is_Q_with_Christmas', 'is_Q_with_Any_Holiday']\n",
    "df[holiday_cols] = df.apply(check_major_holidays, axis=1, result_type='expand')\n",
    "\n",
    "# Drop the temporary numeric year column\n",
    "df.drop(columns=['Year_n'], inplace=True)\n",
    "\n",
    "print(\"\\nHoliday features added:\")\n",
    "print(df[holiday_cols].sum()) # show how many rows have these flags set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/processed/base_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
