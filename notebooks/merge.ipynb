{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cluster import KMeans # for clustering routes\n",
    "import statsmodels.api as sm # useful for regression diagnostics\n",
    "\n",
    "from econml.dml import LinearDML, CausalForestDML\n",
    "from econml.cate_interpreter import SingleTreeCateInterpreter\n",
    "\n",
    "# --- Plotting Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_col(series):\n",
    "    if series.dtype == 'object':\n",
    "        series = series.str.replace('%', '', regex=False)\n",
    "        series = series.str.replace(',', '.', regex=False) \n",
    "        series = series.str.replace(',', '', regex=False)\n",
    "    numeric_series = pd.to_numeric(series, errors='coerce')\n",
    "    return numeric_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1 = pd.read_csv('../datasets/processed/df1.csv', sep=',', decimal='.')\n",
    "df_t7 = pd.read_csv('../datasets/processed/df7.csv', sep=',', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting df_t1['citymarketid_1'] before cleaning/conversion ---\n",
      "Data Type: object\n",
      "Non-Null Count: 115032\n",
      "Unique values (sample):\n",
      "['32,575' '32,467' '31,703' '30,977' '30,397' '32,211' '30,721' '32,457'\n",
      " '30,194' '33,570' '30,325' '31,454' '31,453' '31,057' '31,295' '30,693'\n",
      " '30,466' '34,057' '31,650' '30,559' '30,423' '33,195' '33,192' '31,714'\n",
      " '30,994' '33,495' '31,136' '30,792' '34,614' '32,337' '31,066' '30,647'\n",
      " '34,100' '31,135' '33,105' '30,529' '31,123' '33,198' '30,713' '33,342'\n",
      " '33,214' '30,852' '34,492' '30,140' '34,321' '30,154' '30,198' '33,044'\n",
      " '31,995' '33,244']\n",
      "\n",
      "--- Applying cleaning steps to citymarketid_1 ---\n",
      "Removing commas...\n",
      "Unique values (sample) AFTER cleaning:\n",
      "['32575' '32467' '31703' '30977' '30397' '32211' '30721' '32457' '30194'\n",
      " '33570' '30325' '31454' '31453' '31057' '31295' '30693' '30466' '34057'\n",
      " '31650' '30559' '30423' '33195' '33192' '31714' '30994' '33495' '31136'\n",
      " '30792' '34614' '32337' '31066' '30647' '34100' '31135' '33105' '30529'\n",
      " '31123' '33198' '30713' '33342' '33214' '30852' '34492' '30140' '34321'\n",
      " '30154' '30198' '33044' '31995' '33244']\n",
      "\n",
      "--- Attempting Conversion to Int64 ---\n",
      "\n",
      "--- Checking df_t1['citymarketid_1'] AFTER conversion ---\n",
      "Data Type: Int64\n",
      "Non-Null Count: 115032\n",
      "Null Count: 0\n",
      "\n",
      "--- Verifying types before merge ---\n",
      "df_t1 citymarketid_1 dtype: Int64, Non-Nulls: 115032\n",
      "df_t1 citymarketid_2 dtype: Int64, Non-Nulls: 115032\n",
      "df_t7 citymarketid dtype: Int64, Non-Nulls: 22619\n",
      "\n",
      "Conversion appears successful, proceeding with merge...\n",
      "Number of rows in df_t7_final before duplicate check: 22619\n",
      "Number of duplicate key sets found in df_t7_final: 2798\n",
      "Handling duplicates by averaging values...\n",
      "Number of rows in df_t7_final after averaging duplicates: 19821\n",
      "\n",
      "--- Final merged DataFrame info: ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115032 entries, 0 to 115031\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Year                 115032 non-null  Int64  \n",
      " 1   quarter              115032 non-null  Int64  \n",
      " 2   citymarketid_1       115032 non-null  Int64  \n",
      " 3   citymarketid_2       115032 non-null  Int64  \n",
      " 4   city1                115032 non-null  object \n",
      " 5   city2                115032 non-null  object \n",
      " 6   nsmiles              115032 non-null  int64  \n",
      " 7   passengers           115032 non-null  int64  \n",
      " 8   fare                 115032 non-null  float64\n",
      " 9   carrier_lg           115032 non-null  object \n",
      " 10  large_ms             115032 non-null  float64\n",
      " 11  fare_lg              115032 non-null  float64\n",
      " 12  carrier_low          115032 non-null  object \n",
      " 13  lf_ms                115032 non-null  float64\n",
      " 14  fare_low             115032 non-null  float64\n",
      " 15  origin_fare_premium  112876 non-null  float64\n",
      " 16  origin_perc_lcc_pax  112876 non-null  float64\n",
      " 17  dest_fare_premium    112858 non-null  float64\n",
      " 18  dest_perc_lcc_pax    112858 non-null  float64\n",
      " 19  route_id             115032 non-null  object \n",
      "dtypes: Int64(4), float64(9), int64(2), object(5)\n",
      "memory usage: 18.0+ MB\n",
      "\n",
      "--- Final missing values AFTER MERGE: ---\n",
      "Year                      0\n",
      "quarter                   0\n",
      "citymarketid_1            0\n",
      "citymarketid_2            0\n",
      "city1                     0\n",
      "city2                     0\n",
      "nsmiles                   0\n",
      "passengers                0\n",
      "fare                      0\n",
      "carrier_lg                0\n",
      "large_ms                  0\n",
      "fare_lg                   0\n",
      "carrier_low               0\n",
      "lf_ms                     0\n",
      "fare_low                  0\n",
      "origin_fare_premium    2156\n",
      "origin_perc_lcc_pax    2156\n",
      "dest_fare_premium      2174\n",
      "dest_perc_lcc_pax      2174\n",
      "route_id                  0\n",
      "dtype: int64\n",
      "\n",
      "--- Final missing values AFTER HANDLING: ---\n",
      "Year                   0\n",
      "quarter                0\n",
      "citymarketid_1         0\n",
      "citymarketid_2         0\n",
      "city1                  0\n",
      "city2                  0\n",
      "nsmiles                0\n",
      "passengers             0\n",
      "fare                   0\n",
      "carrier_lg             0\n",
      "large_ms               0\n",
      "fare_lg                0\n",
      "carrier_low            0\n",
      "lf_ms                  0\n",
      "fare_low               0\n",
      "origin_fare_premium    0\n",
      "origin_perc_lcc_pax    0\n",
      "dest_fare_premium      0\n",
      "dest_perc_lcc_pax      0\n",
      "route_id               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inspecting df_t1['citymarketid_1'] before cleaning/conversion ---\")\n",
    "print(\"Data Type:\", df_t1['citymarketid_1'].dtype)\n",
    "print(\"Non-Null Count:\", df_t1['citymarketid_1'].notna().sum())\n",
    "print(\"Unique values (sample):\")\n",
    "try:\n",
    "    unique_vals = df_t1['citymarketid_1'].unique()\n",
    "    print(unique_vals[:50]) # shows values like '32,575'\n",
    "except Exception as e:\n",
    "    print(f\"Could not display unique values: {e}\")\n",
    "\n",
    "\n",
    "# --- Clean the string column BEFORE converting ---\n",
    "print(\"\\n--- Applying cleaning steps to citymarketid_1 ---\")\n",
    "\n",
    "# 1. Ensure it's treated as string and strip whitespace \n",
    "df_t1['citymarketid_1'] = df_t1['citymarketid_1'].astype(str).str.strip()\n",
    "\n",
    "# 2. *** FIX: Remove commas used as thousands separators ***\n",
    "print(\"Removing commas...\")\n",
    "df_t1['citymarketid_1'] = df_t1['citymarketid_1'].str.replace(',', '', regex=False)\n",
    "\n",
    "# Opt. Check unique values again AFTER cleaning to verify\n",
    "print(\"Unique values (sample) AFTER cleaning:\")\n",
    "unique_vals_cleaned = df_t1['citymarketid_1'].unique()\n",
    "print(unique_vals_cleaned[:50])\n",
    "\n",
    "# --- Convert to numeric AFTER cleaning ---\n",
    "print(\"\\n--- Attempting Conversion to Int64 ---\")\n",
    "df_t1['citymarketid_1'] = pd.to_numeric(df_t1['citymarketid_1'], errors='coerce').astype('Int64')\n",
    "# Also convert citymarketid_2 and df_t7['citymarketid']\n",
    "df_t1['citymarketid_2'] = pd.to_numeric(df_t1['citymarketid_2'], errors='coerce').astype('Int64')\n",
    "df_t7['citymarketid'] = pd.to_numeric(df_t7['citymarketid'], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "# --- Check conversion result ---\n",
    "print(\"\\n--- Checking df_t1['citymarketid_1'] AFTER conversion ---\")\n",
    "print(\"Data Type:\", df_t1['citymarketid_1'].dtype)\n",
    "print(\"Non-Null Count:\", df_t1['citymarketid_1'].notna().sum())\n",
    "print(\"Null Count:\", df_t1['citymarketid_1'].isna().sum()) \n",
    "\n",
    "\n",
    "# --- Verify types before merge ---\n",
    "print(\"\\n--- Verifying types before merge ---\")\n",
    "print(f\"df_t1 citymarketid_1 dtype: {df_t1['citymarketid_1'].dtype}, Non-Nulls: {df_t1['citymarketid_1'].notna().sum()}\")\n",
    "print(f\"df_t1 citymarketid_2 dtype: {df_t1['citymarketid_2'].dtype}, Non-Nulls: {df_t1['citymarketid_2'].notna().sum()}\")\n",
    "print(f\"df_t7 citymarketid dtype: {df_t7['citymarketid'].dtype}, Non-Nulls: {df_t7['citymarketid'].notna().sum()}\")\n",
    "\n",
    "\n",
    "# --- Proceed with merge only if conversion was successful ---\n",
    "if df_t1['citymarketid_1'].notna().sum() > 0:\n",
    "    print(\"\\nConversion appears successful, proceeding with merge...\")\n",
    "\n",
    "    # Ensure 'Year', 'quarter' have matching types\n",
    "    df_t1['Year'] = pd.to_numeric(df_t1['Year'], errors='coerce').astype('Int64')\n",
    "    df_t1['quarter'] = pd.to_numeric(df_t1['quarter'], errors='coerce').astype('Int64')\n",
    "    df_t7['Year'] = pd.to_numeric(df_t7['Year'], errors='coerce').astype('Int64')\n",
    "    df_t7['quarter'] = pd.to_numeric(df_t7['quarter'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # Clean T7 columns and rename (using correct T7 column names from info())\n",
    "    df_t7_clean = df_t7[['Year', 'quarter', 'citymarketid', 'TotalPerPrem', 'TotalPerLFMkts']].copy()\n",
    "    df_t7_clean.rename(columns={'TotalPerPrem': 'city_fare_premium',\n",
    "                          'TotalPerLFMkts': 'city_perc_lcc_pax'}, inplace=True)\n",
    "    df_t7_final = df_t7_clean[['Year', 'quarter', 'citymarketid', 'city_fare_premium', 'city_perc_lcc_pax']]\n",
    "\n",
    "print(f\"Number of rows in df_t7_final before duplicate check: {len(df_t7_final)}\")\n",
    "key_cols = ['Year', 'quarter', 'citymarketid']\n",
    "\n",
    "# --- Check for duplicates based on merge keys ---\n",
    "num_duplicates = df_t7_final.duplicated(subset=key_cols).sum()\n",
    "print(f\"Number of duplicate key sets found in df_t7_final: {num_duplicates}\")\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    print(\"Handling duplicates by averaging values...\")\n",
    "    value_cols = ['city_fare_premium', 'city_perc_lcc_pax'] \n",
    "    \n",
    "    # Group by keys, calculate mean, reset index\n",
    "    df_t7_final = df_t7_final.groupby(key_cols, as_index=False)[value_cols].mean()\n",
    "    print(f\"Number of rows in df_t7_final after averaging duplicates: {len(df_t7_final)}\")\n",
    "\n",
    "    # Merge for Origin City\n",
    "    df_merged = pd.merge(df_t1, df_t7_final,\n",
    "                         left_on=['Year', 'quarter', 'citymarketid_1'],\n",
    "                         right_on=['Year', 'quarter', 'citymarketid'],\n",
    "                         how='left')\n",
    "    df_merged.rename(columns={'city_fare_premium': 'origin_fare_premium',\n",
    "                              'city_perc_lcc_pax': 'origin_perc_lcc_pax'}, inplace=True)\n",
    "\n",
    "    # Merge for Destination City\n",
    "    df_merged = pd.merge(df_merged, df_t7_final,\n",
    "                         left_on=['Year', 'quarter', 'citymarketid_2'],\n",
    "                         right_on=['Year', 'quarter', 'citymarketid'],\n",
    "                         how='left', suffixes=('_orig_temp', ''))\n",
    "    df_merged.rename(columns={'city_fare_premium': 'dest_fare_premium',\n",
    "                              'city_perc_lcc_pax': 'dest_perc_lcc_pax'}, inplace=True)\n",
    "\n",
    "    # Clean up columns\n",
    "    df_merged.drop(columns=['citymarketid_orig_temp', 'citymarketid'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Create route_id\n",
    "    df_merged['route_id'] = df_merged['citymarketid_1'].astype(str) + '_' + df_merged['citymarketid_2'].astype(str)\n",
    "\n",
    "    # Assign to df and check results\n",
    "    df = df_merged.copy()\n",
    "    print(\"\\n--- Final merged DataFrame info: ---\")\n",
    "    df.info()\n",
    "    print(\"\\n--- Final missing values AFTER MERGE: ---\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Handle remaining NAs (from non-matches)\n",
    "    fill_cols = ['origin_fare_premium', 'origin_perc_lcc_pax', 'dest_fare_premium', 'dest_perc_lcc_pax']\n",
    "    for col in fill_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0) # fill with 0 for no matching city market ids\n",
    "    \n",
    "    print(\"\\n--- Final missing values AFTER HANDLING: ---\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "else:\n",
    "    print(\"\\nMerge skipped: df_t1['citymarketid_1'] conversion still failed after cleaning.\")\n",
    "    print(\"If commas were removed and it still fails, re-inspect unique values for other issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
